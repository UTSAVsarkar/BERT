{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e22ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b01c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\n",
    "    \"negative\": 0,\n",
    "    \"positive\": 1\n",
    "})\n",
    "\n",
    "# âš¡ Reduce size for CPU (remove if GPU available)\n",
    "df = df.sample(12000, random_state=42)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"review\"].tolist(),\n",
    "    df[\"sentiment\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"sentiment\"],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bbced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=MAX_LEN\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68344a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be389a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
    "test_dataset = IMDBDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515fcaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb38a7c759a49b0a621912479acbb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65264786",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,   # CPU safe\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a502b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b96d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894b577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 07:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>0.374668</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>0.853977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.3978362528483073, metrics={'train_runtime': 422.3691, 'train_samples_per_second': 22.729, 'train_steps_per_second': 2.841, 'total_flos': 317921756774400.0, 'train_loss': 0.3978362528483073, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043683db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3746684193611145,\n",
       " 'eval_accuracy': 0.84625,\n",
       " 'eval_f1': 0.8539770478828651,\n",
       " 'eval_runtime': 27.0107,\n",
       " 'eval_samples_per_second': 88.854,\n",
       " 'eval_steps_per_second': 11.107,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b7c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70897720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    # ðŸ”¥ move inputs to same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    return \"Positive\" if probs[0][1].item() > probs[0][0].item() else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7175b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"This movie was absolutely fantastic, I loved every moment of it.\",\n",
    "    \"The film was boring, slow, and a complete waste of time.\",\n",
    "    \"Amazing performances and a very emotional storyline.\",\n",
    "    \"I didnâ€™t like the movie at all, the plot made no sense.\",\n",
    "    \"It was okay, not great but not terrible either.\",\n",
    "    \"The cinematography was beautiful, but the story was weak.\",\n",
    "    \"Terrible acting ruined what could have been a good movie.\",\n",
    "    \"One of the best movies I have seen in years!\",\n",
    "    \"The movie started well but became disappointing towards the end.\",\n",
    "    \"I would not recommend this movie to anyone.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed4321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This movie was absolutely fantastic, I loved every moment of it.\n",
      "Prediction: Positive\n",
      "------------------------------------------------------------\n",
      "Review: The film was boring, slow, and a complete waste of time.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: Amazing performances and a very emotional storyline.\n",
      "Prediction: Positive\n",
      "------------------------------------------------------------\n",
      "Review: I didnâ€™t like the movie at all, the plot made no sense.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: It was okay, not great but not terrible either.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: The cinematography was beautiful, but the story was weak.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: Terrible acting ruined what could have been a good movie.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: One of the best movies I have seen in years!\n",
      "Prediction: Positive\n",
      "------------------------------------------------------------\n",
      "Review: The movie started well but became disappointing towards the end.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n",
      "Review: I would not recommend this movie to anyone.\n",
      "Prediction: Negative\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in test_sentences:\n",
    "    print(f\"Review: {text}\")\n",
    "    print(\"Prediction:\", predict_sentiment(text))\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
